{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905b4a5c-2e1b-495e-a022-d7e31fcc573d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "✓ HuggingFace authentication successful\n",
      "Transformers version: 4.55.3\n",
      "=== Environment Validation ===\n",
      "CUDA_VISIBLE_DEVICES: 0\n",
      "PYTORCH_CUDA_ALLOC_CONF: expandable_segments:True\n",
      "torch.cuda.is_available(): True\n",
      "torch.cuda.get_device_name(0): NVIDIA H100 PCIe\n",
      "Effective DTYPE: torch.bfloat16\n",
      "✓ Dataset loaded: 5000 rows\n",
      "\n",
      "--- Running experiments for: pythia-410m (EleutherAI/pythia-410m) ---\n",
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n",
      "ERROR running pythia-410m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Finished processing pythia-410m.\n",
      "\n",
      "--- Running experiments for: bloom-560m (bigscience/bloom-560m) ---\n",
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n",
      "WARNING:root:Missing key for a weight matrix in pretrained, filled in with an empty tensor: pos_embed.W_pos\n",
      "ERROR running bloom-560m: CUDA error: CUDA-capable device(s) is/are busy or unavailable\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "Finished processing bloom-560m.\n",
      "\n",
      "--- Running experiments for: gpt-neox-20b (EleutherAI/gpt-neox-20b) ---\n",
      "Loading checkpoint shards: 100%|████████████████| 46/46 [00:14<00:00,  3.18it/s]\n",
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n"
     ]
    }
   ],
   "source": [
    "!python script1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45365b22-d684-45e0-9f79-51b6e0219214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c96efe-a2b6-4e2b-8578-3bf4ab0112f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
